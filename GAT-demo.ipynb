{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a80ee415-364c-4f83-ba88-0290b3cd8f82",
   "metadata": {},
   "source": [
    "# Self-evaluation of Generation Augmented by Tools\n",
    "\n",
    "---\n",
    "\n",
    "## Demonstration notebook\n",
    "\n",
    "-----\n",
    "\n",
    "Retrieval Augmented Generation (RAG) and, more generally, Generation Aumented by Tools (GAT) can greatly improve LLM capabilities on non-language related tasks and tasks that require retrieving information from databases, for example.\n",
    "\n",
    "However, there are already multiple LLM choices and the vast amount of interest in the field means more will come. While public datasets are available to test general LLM performance, it is difficult to evaluate GAT specifically developed for a business task of interest.\n",
    "\n",
    "This work introduces a method for self-evaluation of GAT. This is done by providing tools that allow the LLM to generate domain-specific responses and verify that those are correct. There are many problems whose solution may be difficult to compute but it's correctness is easy to verify.\n",
    "\n",
    "\n",
    "## Running on AWS SageMaker\n",
    "\n",
    "This notebook runs on AWS Sagemaker Studio in the Data Science 3.0 image.\n",
    "\n",
    "\n",
    "### Claude notes\n",
    "\n",
    "Allowed Claude types are string, integer, number\n",
    "\n",
    "                \"priority\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"minimum\": 1,\n",
    "                    \"maximum\": 5,\n",
    "                    \"default\": 3,\n",
    "                    \"description\": \"The priority level of the note (1-5).\"\n",
    "                },\n",
    "                \"is_public\": {\n",
    "                    \"type\": \"boolean\",\n",
    "                    \"default\": False,\n",
    "                    \"description\": \"Indicates whether the note is publicly accessible.\"\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fb86f0-804a-448c-81d6-c69259eb916a",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168ad6d-475e-4595-b756-fca7722ea8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import gradio as gr\n",
    "    import qrcode\n",
    "except:\n",
    "    %pip install gradio -q\n",
    "    %pip uninstall typing-extensions -y -q\n",
    "    %pip install -U typing-extensions -q\n",
    "    %pip install matplotlib -q\n",
    "    %pip install qrcode\n",
    "    %pip install duckdb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f36e6-3638-4ed3-945c-89f2e9e85241",
   "metadata": {},
   "source": [
    "## Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c2297-5dd1-4112-a029-2f624419dca2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import gat_llm.llm_invoker as inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4905a3-55a8-4fd3-b6ec-b4dcdf63856e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = botocore.client.Config(connect_timeout=9000, read_timeout=9000, region_name=\"us-west-2\")  # us-east-1  us-west-2\n",
    "bedrock_client = boto3.client(service_name='bedrock-runtime', config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8bbb8d-233c-44cc-8681-e5f38da8a3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fe807f-dc36-4492-bf9a-3cfdc49c1bb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outdated\n",
    "# llm = inv.LLM_Provider.get_llm(bedrock_client, 'Claude 2.1')\n",
    "# llm_name = 'Llama2 70b'\n",
    "\n",
    "# Current\n",
    "# llm_name = 'Mistral Mixtral 8x7B'\n",
    "# llm_name = 'Mistral Large v1'\n",
    "# llm_name = 'Claude 3 Haiku - Bedrock'\n",
    "# llm_name = \"GPT 4o - OpenAI\"  # \"GPT 3.5 - OpenAI\" \"GPT 4o - OpenAI\"\n",
    "# llm_name = \"GPT 4o mini - OpenAI\"\n",
    "\n",
    "llm_name = 'Claude 3.5 Sonnet - Anthropic'\n",
    "llm_name = 'Claude 3.5 Sonnet - Bedrock'\n",
    "# llm_name = 'Claude 3.5 Haiku - Anthropic'\n",
    "# llm_name = 'Sabia3 - Maritaca'\n",
    "# llm_name = 'Amazon Nova Pro 1.0 - Bedrock'\n",
    "\n",
    "use_native_LLM_tools = True\n",
    "\n",
    "# llm_name = 'Llama3_1 405b instruct'\n",
    "# use_native_LLM_tools = False\n",
    "\n",
    "llm = inv.LLM_Provider.get_llm(bedrock_client, llm_name)\n",
    "query_llm = inv.LLM_Provider.get_llm(bedrock_client, llm_name)\n",
    "\n",
    "# enable use_native_LLM_tools if the LLM has native support for tool use, like Claude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e4523c-01ec-4aef-93bf-c342c090d984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ans = llm(\"and at night? Enclose your answer within <my_ans></my_ans> tags. Then explain further.\",\n",
    "          chat_history=[[\"What color is the sky?\", \"Blue\"]],\n",
    "          system_prompt=\"You are a very knowledgeable truck driver. Use a strong truck driver's language and make sure to mention your name is Jack.\",\n",
    "          postpend=\"Such\" if not llm_name.startswith(\"Command\") else \"\",\n",
    "          # extra_stop_sequences=['</my_ans>']\n",
    "         )\n",
    "\"\"\"\n",
    "prev = \"\"\n",
    "for x in ans:\n",
    "    cur_ans = x\n",
    "    # print(cur_ans.replace(prev, ''))\n",
    "    # prev = cur_ans\n",
    "    print('.', end='')\n",
    "print('\\n')\n",
    "print(x)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64223c0-cb19-416d-b793-bd89838fc6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.debug_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdb4abd-c897-40b2-be6f-5651b5ca4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: While developing the model parse function\n",
    "\"\"\"\n",
    "response = llm.bedrock_client.invoke_model_with_response_stream(\n",
    "    modelId=llm.model_id, body=json.dumps(llm.debug_body)\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9696b121-176a-4f98-9137-9b8421b59e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_results = [x for x in response[\"body\"]]\n",
    "# all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36bae3b-cf71-454e-a308-09ec75b20b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gen = llm._response_gen(all_results)\n",
    "for x in gen:\n",
    "    pass\n",
    "x\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6c4024-4d8d-43ff-9daf-bdc1142ffdd4",
   "metadata": {},
   "source": [
    "## Initialize Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2090c8-5749-4e2f-9087-95e36f4582db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gat_llm.tools.base import LLMTools\n",
    "from gat_llm.prompts.prompt_generator import RAGPromptGenerator\n",
    "lt = LLMTools(query_llm=query_llm)\n",
    "\n",
    "tool_descriptions = lt.get_tool_descriptions()\n",
    "\n",
    "# Uncomment to take a look at all descriptions\n",
    "# print(tool_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaea491-a939-462d-aed1-3b34ad980ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in lt.tools if len(x.tool_description['description']) > 1280]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a2488-64e7-48ee-b4de-bb1dd54a4ec7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rpg = RAGPromptGenerator(use_native_tools=use_native_LLM_tools)\n",
    "\n",
    "# Uncomment to look at the base prompt\n",
    "# print(rpg.prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f6a96-edd5-4fe4-945d-4ba7e2693720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_prompt = rpg.prompt.replace('{{TOOLS}}', tool_descriptions)\n",
    "\n",
    "# Uncomment to take a look at the final prompt\n",
    "# print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4dff46-62d9-48c8-8893-f5cca87faa28",
   "metadata": {},
   "source": [
    "### Test native tool calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5c1f4-5467-4eec-8575-d7fabaf42ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_tools = [x.tool_description for x in lt.tools]\n",
    "\n",
    "ans = llm(\n",
    "    \"What date will it be 10 days from now? Today is June 4, 2024. Use your tool do_date_math. Before calling any tools, explain your thoughts.\",\n",
    "    # \"What date will it be 10 days from now? Today is June 4, 2024. What tool is necessary? Do NOT call tools or functions.\",\n",
    "    chat_history=[[\"What color is the sky?\", \"Blue\"]],\n",
    "    system_prompt=\"You are a helpful assistant. Prefer to use tools when possible. Never mention tool names in the answer.\",\n",
    "    # postpend=\"Such\",\n",
    "    tools=cur_tools,\n",
    "    tool_invoker_fn=lt.invoke_tool,\n",
    "    # extra_stop_sequences=['</my_ans>']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb2b67a-15d8-40b9-84d7-0ea943cb5850",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "prev = \"\"\n",
    "for x in ans:\n",
    "    cur_ans = x\n",
    "    # print(cur_ans.replace(prev, ''))\n",
    "    # prev = cur_ans\n",
    "    print('.', end='')\n",
    "print(cur_ans)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07338521-2204-458b-a5b8-fe0f71a30bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84400033-6d6d-45d2-ac9a-2ab1b8348398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ans = [x for x in ans[\"body\"]]\n",
    "# for x in llm._response_gen(all_ans):\n",
    "#    print(x)\n",
    "# for x in llm._response_gen(all_ans):\n",
    "#    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547f2750-d91f-4cb3-8538-7c77f7d6b83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.debug_body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76bd6eb-1fbe-484b-8117-12b2f52846c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEBUG: While developing the model parse function\n",
    "\n",
    "# llm.model_id = 'cohere.command-r-v1:0'\n",
    "\"\"\"\n",
    "response = llm.bedrock_client.invoke_model_with_response_stream(\n",
    "    modelId=llm.model_id, body=json.dumps(llm.debug_body)\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de7ddf7-8f3d-4c6b-9272-fcbb3db3d815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef48aec-e3c7-48f3-ae86-04f765adfd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "all_results = [x for x in response[\"body\"]]\n",
    "all_results\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd85fb0-4ba5-4cc1-9d8a-e2987a44ea06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f003af-2957-47aa-ad51-f0b71f821df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "gen = llm._response_gen(all_results)\n",
    "for x in gen:\n",
    "    pass\n",
    "x\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f88a23a-9d3b-4cb0-aa4f-dc0b86ae8010",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.cur_tool_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bda3ecc-21be-4201-8ac6-d3eea0b08a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03b5e1c1-c70f-48d4-b691-567c74c46a95",
   "metadata": {},
   "source": [
    "### Test tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c0bf96-594e-43f7-8dfb-fd479b6fad0e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ans = lt.invoke_tool(\n",
    "    'get_url_content',\n",
    "    internet_urls='https://g1.globo.com/',\n",
    "    return_all_visible_html=\"false\",\n",
    "    recursion_level=0,\n",
    "    recursion_regex_condition=r\"noticia\",\n",
    "    # prompt=\"Summarize the contents.\"\n",
    ")\n",
    "with open(\"debug.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(ans)\n",
    "# print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca90eba1-8c64-41a0-a4b6-99afcf420a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ans = lt.invoke_tool('use_ffmpeg', ffmpeg_arguments=\"-i input.mp4 -ss 10 -t 20 output.mp4\")\n",
    "# print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec25b4-a40e-4c98-9592-8fcad72835c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ans = lt.invoke_tool('read_write_user_details', action=\"READ\", username=\"None\", contents=\"\")\n",
    "# print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6384d980-df58-449b-b4a8-d81c2701d8f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ans = lt.invoke_tool('make_qr_code', qr_text='Hello World!Hello World!Hello World!Hello World!Hello World!Hello World!Hello World!Hello World!Hello World!Hello World!Hello World!')\n",
    "# print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc5c014-fde9-478f-bbe9-984995553fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "f = r\"\"\"test.txt\n",
    "test.txt\n",
    "\"\"\"\n",
    "# ans = lt.invoke_tool('read_local_files', path_to_files=f)\n",
    "# print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d30020-35fd-4fe5-9b28-fc1ab3c0eeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = '/root/Experiments/llm-Claude-tests/meeting_notes/'\n",
    "# ans = lt.invoke_tool('read_file_names_in_local_folder', path_to_folder=f)\n",
    "# print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdce006-15a0-433f-ac22-eb28d01f2b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from tools.query_database import SampleOrder_LLM_DB\n",
    "odb = SampleOrder_LLM_DB()\n",
    "\n",
    "print(odb.get_full_database_description())\n",
    "\n",
    "df = odb.sql_query('''\n",
    "select * from tblSales\n",
    "limit 10\n",
    "''')\n",
    "\n",
    "df\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e07887-58c5-4dc2-9571-7f5c3c518275",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d12f0b-1cd8-4c7e-a36d-5a458da5734e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "027d3932-8481-4b27-9817-075ff91ad226",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Initialize Interfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b373a61d-4029-44ce-a448-efe5641d2d6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gat_llm.llm_interface import LLMInterface\n",
    "li = LLMInterface(\n",
    "    system_prompt=system_prompt,\n",
    "    llm=llm,\n",
    "    llm_tools=lt,\n",
    "    rpg=rpg\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d7f99e-64e7-4d60-8e64-6d920b57b555",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de0d356-9665-48fd-b783-02a9ba1e6418",
   "metadata": {},
   "source": [
    "# Run locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976740fe-acef-40f7-ac72-064b27a88f25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = \"\"\" Answer the following <questions>:\n",
    "<questions>\n",
    "<question>What day is today?</question>\n",
    "<question>Make a plot of y=x^2</question>\n",
    "</questions>\"\"\"\n",
    "\n",
    "q = \"What are the solutions to the equation: x^2 - 1 = 0\"\n",
    "q1 = \"\"\"Generate 3 questions that you can answer using your tools.\n",
    "After generating the questions, compute the correct answer using the tools.\n",
    "Then, output your answer in the format:\n",
    "<question_answers>\n",
    "<question_answer>\n",
    "<question>(Question that you can answer with your tools)</question>\n",
    "<expected_answer>(Correct answer, calculated using the tools)</expected_answer>\n",
    "</question_answer>\n",
    "</question_answers>\"\"\"\n",
    "q2 = \"I live in Florence IT. Fetch from the internet relevant news today. Summarize the news for me.\"\n",
    "\n",
    "# ans = li.chat_with_function_caller(q, image=None, ui_history=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d633b14c-787a-441a-8f46-d8ef55ce5331",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# uncomment this to see the answer in the notebook\n",
    "import time\n",
    "t0 = time.time()\n",
    "\n",
    "prev = \"\"\n",
    "for x in ans:\n",
    "    cur_ans = x[3][-1][1]\n",
    "    try:\n",
    "        print(cur_ans.replace(prev, ''))\n",
    "    except:\n",
    "        pass\n",
    "    prev = cur_ans\n",
    "    # print('.', end='')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856fb6ca-8f9b-4441-b057-e9fbb42189ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(cur_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7a6ef0-b30f-4743-8784-015f07ff978e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use your tools to verify if the solution satisfies all requirements of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c69e779-7d8b-4290-8278-5612bdcd35b2",
   "metadata": {},
   "source": [
    "# Run with Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1930f1-840c-4985-958a-9670c32ab251",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples=[\n",
    "    'Give me a summary of your tools and what they do. Answer with a table.',\n",
    "    'What is in the image?',\n",
    "    \"What day is today?\",\n",
    "    \"What day was it 10 days ago?\",\n",
    "    \"Make a simple flowchart with A -> B -> C\",\n",
    "    \"If I invest $100 with an interest rate of 1% per month, how much will I have in 3 years?\",\n",
    "    \"Make a plot of y=x^2\",\n",
    "    \"What are the solutions to the equation: x^2 - 1 = 0\",\n",
    "    \"If Mark has 3 times more apples than John and they have 40 apples in total, how many apples do each have?\",\n",
    "    \"Evaluate the expression exp(2)+sin(4)\",\n",
    "    'faca um qr code estilo vcard para mim. me pergunte as informacoes que precisar',\n",
    "    \"I live in Florence IT. Fetch from the internet relevant news today.\",\n",
    "    \"Summarize the economics news in https://www.economist.com/ and https://www.theguardian.com/business/economics . Check which articles show on both or only on one. Answer with a table.\",\n",
    "    \"List all your tools. Summarize what each tool does and generate 3 sample questions that it could answer. Answer with a table.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02491f-e990-4f1d-943c-42413647360e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def msg_forward_func(msg, img_input, history, system_prompt_prepend, request: gr.Request):\n",
    "    # print(request)\n",
    "    li.system_prompt = system_prompt + '\\n' + system_prompt_prepend\n",
    "    if msg is None or msg.strip() == \"\":\n",
    "        msg = \"perform task\"\n",
    "\n",
    "    ans_gen = li.chat_with_function_caller(msg, img_input, history, username=request.username)\n",
    "    for x in ans_gen:\n",
    "        txtbox, scratchpad_info, img_input, cur_history = x\n",
    "        yield txtbox, scratchpad_info, img_input, cur_history, []\n",
    "\n",
    "    chat_id = cur_history[0][\"content\"]\n",
    "    raw_history = li.history_log[chat_id]\n",
    "    yield txtbox, scratchpad_info, img_input, cur_history, {\"raw_history\": raw_history}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488cfdb3-a2ad-4928-b814-fc4f166178de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    with gr.Column():\n",
    "        with gr.Row():\n",
    "            with gr.Column(scale=2):\n",
    "                chatbot = gr.Chatbot(label=\"Assistant\", elem_id=\"chatbot\", type=\"messages\", height=600)\n",
    "            with gr.Column(scale=1):\n",
    "                image_input = gr.Image(label='Input Image')\n",
    "\n",
    "        msg2 = gr.Dropdown(\n",
    "            examples, label=\"Question\", info=\"Select or type a question\", allow_custom_value=True\n",
    "        )\n",
    "\n",
    "        with gr.Row():\n",
    "            send_btn = gr.Button(\"Send\")\n",
    "            clear = gr.ClearButton([msg2, image_input, chatbot])\n",
    "\n",
    "        scratchpad = gr.Textbox(label=\"Scratchpad\")\n",
    "        sys_prompt_txt = gr.Text(label=\"System prompt prepend\", value=\"\")\n",
    "    raw_history = gr.JSON(label=\"Raw history\", open=False)\n",
    "\n",
    "    gr.on(\n",
    "        # triggers=[msg.submit, send_btn.click],\n",
    "        triggers=[send_btn.click],\n",
    "        fn=msg_forward_func,  # li.chat_with_function_caller,  # respond,\n",
    "        inputs=[msg2, image_input, chatbot, sys_prompt_txt],\n",
    "        outputs=[msg2, scratchpad, image_input, chatbot, raw_history],\n",
    "        concurrency_limit=20\n",
    "    )\n",
    "\n",
    "demo.queue().launch(show_api=False, share=False, inline=False)\n",
    "# demo.queue().launch(show_api=False, share=True, inline=False, auth=(\"proj\", \"proj7645\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26a9b0c-353f-48cf-8c72-54c0bbcc3b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.cur_tool_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f33dec-2e75-4c29-9d08-9df8f1c6d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lt.invoke_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e844b6-998d-47fe-8cea-37ef0db6dc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad0192-8bdf-43a5-835b-4ed1c60dc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm.debug_body"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
